<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Leo&#39;s sharing space</title>
        <link>https://example.org/post/</link>
        <description>Recent content in Posts on Leo&#39;s sharing space</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sat, 24 May 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://example.org/post/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Bayes&#39; Theory and Bayesian Inference</title>
        <link>https://example.org/post/bayes_theory/</link>
        <pubDate>Sat, 24 May 2025 00:00:00 +0000</pubDate>
        
        <guid>https://example.org/post/bayes_theory/</guid>
        <description>&lt;img src="https://example.org/post/bayes_theory/Minecraft_view.jpg" alt="Featured image of post Bayes&#39; Theory and Bayesian Inference" /&gt;&lt;h2 id=&#34;law-of-total-probability&#34;&gt;Law of total probability
&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s say we have a set of mutually exclusive probable events ${B_i : i=1,2,3,&amp;hellip;,n }$. The sum of the probabilities of these events is equal to 1, i.e. $$\sum_i P(B_i)=1$$&lt;/p&gt;
&lt;p&gt;Now, if we have another event $A$, we can express the probability of $A$ in terms of the probabilities of $B_i$ and the conditional probabilities of $A$ given $B_i$. This is known as the law of total probability:
$$P(A)=\sum_i P(A|B_i)P(B_i)$$&lt;/p&gt;
&lt;p&gt;Here, as the sum of the probabilities of $B_i$ is equal to 1. The event $A$ must happen in at least one of the $B_i$ events, or the $P(A)$ is equal to 0. We can understand this as the probability of $A$ is the sum of the probabilities of $A$ happening in each of the mutually exclusive events $B_i$.&lt;/p&gt;
&lt;h2 id=&#34;bayes-rule&#34;&gt;Bayes&amp;rsquo; rule
&lt;/h2&gt;&lt;p&gt;For any specific event $B_j$, the probability of both event $A$ and $B_j$ happending is $$P(A,B_j)=P(A|B_j)P(B_j)$$&lt;/p&gt;
&lt;p&gt;Also, we can express the same probability in terms of the conditional probability of $B_j$ given $A$:
$$P(A,B_j)=P(B_j|A)P(A)$$&lt;/p&gt;
&lt;p&gt;Therefore, we can write get this formula:
$$P(A,B_j)=P(A|B_j)P(B_j)=P(B_j|A)P(A)$$&lt;/p&gt;
&lt;p&gt;Here comes the Bayes&amp;rsquo; rule:
$$P(A|B_j)=\frac{P(B_j|A)P(A)}{P(B_j)} \tag{1}$$
$$or$$
$$P(B_j|A)=\frac{P(A|B_j)P(B_j)}{P(A)}$$&lt;/p&gt;
&lt;p&gt;Using the formula (1) as example, we call the $P(A)$ as the prior probability of event $A$ happening. The $P(A|B_j)$ is the posterior probability of event $A$ given that event $B_j$ has happened. The $P(B_j|A)$ is the likelihood of event $B_j$ given that event $A$ has happened. The $P(B_j)$ is the marginal probability of event $B_j$.&lt;/p&gt;
&lt;h2 id=&#34;bayesian-inference&#34;&gt;Bayesian inference
&lt;/h2&gt;&lt;p&gt;Bayesian inference is a method of statistical inference in which Bayes&amp;rsquo; theorem is used to update the probability for a hypothesis as more evidence or information becomes available. In Bayesian inference, we start with a prior distribution, which represents our beliefs about the parameters before observing any data. After observing the data, we update our beliefs using Bayes&amp;rsquo; rule to obtain the posterior distribution.&lt;/p&gt;
&lt;p&gt;Using the formula (1) as example, $P(A)$ is the prior distribution of event $A$, which represents our beliefs about the parameters before observing any data. The $P(B_j|A)$ is the likelihood of event $B_j$ given that event $A$ has happened. The $P(B_j)$ is the marginal distribution of event $B_j$. We update our beliefs about the $P(A)$ by observing the data $B_j$ and using Bayes&amp;rsquo; rule to get the posterior probability distribution $P(A|B_j)$.&lt;/p&gt;
&lt;p&gt;There are many types of prior distributions, and also many types of likelihood functions. The choice of prior distribution and likelihood function depends on the problem at hand and the available data. Some combination of prior distribution and likelihood function can lead to a closed-form solution, which means we can derive the exact formula for the posterior distribution, while others may require numerical methods such as Markov Chain Monte Carlo (MCMC) to approximate the posterior distribution. Here, we first introduce the closed-form cases, and then introduce the numerical methods.&lt;/p&gt;
&lt;h3 id=&#34;closed-form-solutions-conjugate-priors&#34;&gt;Closed-form solutions: conjugate priors
&lt;/h3&gt;&lt;h4 id=&#34;beta-prior-and-binomial-likelihood&#34;&gt;Beta prior and binomial likelihood
&lt;/h4&gt;&lt;p&gt;The Beta distribution is a conjugate prior for the binomial likelihood. If we have a binomial likelihood $P(X=k|p)=\binom{n}{k}p^k(1-p)^{n-k}$, where $X$ is the number of successes in $n$ trials and $p$ is the probability of success, we can use a Beta prior $P(p|\alpha,\beta)=\frac{1}{B(\alpha,\beta)}p^{\alpha-1}(1-p)^{\beta-1}$, where $\alpha$ and $\beta$ are the shape parameters of the Beta distribution.&lt;/p&gt;
&lt;p&gt;Using Bayes&amp;rsquo; rule, we can derive the posterior distribution:
$$P(p|X=k)=\frac{P(X=k|p)P(p)}{P(X=k)}$$
Substituting the binomial likelihood and Beta prior, we get:
$$P(p|X=k)=\frac{\binom{n}{k}p^k(1-p)^{n-k}\frac{1}{B(\alpha,\beta)}p^{\alpha-1}(1-p)^{\beta-1}}{P(X=k)} \tag{2}$$&lt;/p&gt;
&lt;p&gt;The numerator of the equation (2) can be simplified as:
$$P(p|X=k)=\frac{1}{P(X=k)}\cdot\frac{1}{B(\alpha,\beta)}\binom{n}{k}p^{k+\alpha-1}(1-p)^{n-k+\beta-1}$$&lt;/p&gt;
&lt;p&gt;Here, the posterior distribution is a function of $p$. The constant $\frac{1}{B(\alpha,\beta)}$, $(_k^n)$, and the $P(X=k)$ are all constants with respect to $p$. Therefore, we can first ignore them when we are only interested in the shape of the posterior distribution. Therefore, we can write the posterior distribution as:
$$P(p|X=k) \propto p^{k+\alpha-1}(1-p)^{n-k+\beta-1} \tag{3}$$&lt;/p&gt;
&lt;p&gt;Here comes the magic part, the posterior distribution is similar to the PDF of Beta distribution, with the shape parameters $\alpha&amp;rsquo; = k + \alpha$ and $\beta&amp;rsquo; = n - k + \beta$:
$$\beta(k+\alpha, n-k+\beta)=\frac{1}{B(k+\alpha,n-k+\beta)}p^{k+\alpha-1}(1-p)^{n-k+\beta}$$&lt;/p&gt;
&lt;p&gt;But missing the Beta function $\frac{1}{B(k+\alpha,n-k+\beta)}$. Interestly, the formula (3) tells us that the posterior distribution is proportional to the $p^{k+\alpha-1}(1-p)^{n-k+\beta-1}$, the constant parts are ignored. In fact, the true posterior distribution should be:
$$P(p|X=k) = constant \cdot p^{k+\alpha-1}(1-p)^{n-k+\beta-1}$$&lt;/p&gt;
&lt;p&gt;To get the constant. We can use the characteristics of a PDF that the integral of the PDF is equal to 1:
$$\int_0^1 P(p|X=k)dp = 1$$
This integral can be solved as:
$$\int_0^1 p^{k+\alpha-1}(1-p)^{n-k+\beta-1}dp = B(k+\alpha, n-k+\beta)$$
Therefore, we can get the constant:
$$constant = \frac{1}{B(k+\alpha, n-k+\beta)}$$
Thus, the posterior distribution is:
$$P(p|X=k) = \frac{1}{B(k+\alpha, n-k+\beta)}p^{k+\alpha-1}(1-p)^{n-k+\beta-1}$$&lt;/p&gt;
&lt;p&gt;Now, we can see that the posterior distribution is a Beta distribution with shape parameters $\alpha&amp;rsquo; = k + \alpha$ and $\beta&amp;rsquo; = n - k + \beta$. This is the closed-form solution for the posterior distribution when using a Beta prior and a binomial likelihood. And this is the reason why we call the Beta distribution a conjugate prior for the binomial likelihood.&lt;/p&gt;
&lt;h4 id=&#34;normal-prior-and-normal-likelihood&#34;&gt;Normal prior and normal likelihood
&lt;/h4&gt;</description>
        </item>
        <item>
        <title>Beta distribution</title>
        <link>https://example.org/post/beta_distribution/</link>
        <pubDate>Wed, 14 May 2025 15:10:48 +0800</pubDate>
        
        <guid>https://example.org/post/beta_distribution/</guid>
        <description>&lt;img src="https://example.org/post/beta_distribution/logcabin.jpg" alt="Featured image of post Beta distribution" /&gt;&lt;h2 id=&#34;beta-distribution&#34;&gt;Beta distribution
&lt;/h2&gt;&lt;p&gt;The Beta distribution is a continuous distribution on the interval (0,1). It is a generalization of the Unif(0,1) distribution.&lt;/p&gt;
&lt;p&gt;An random variable $X$ is said to have the Beta distribution with parameters $a$ and $b$, where $a,b &amp;gt; 0$, if its probability density function (PDF) is:&lt;/p&gt;
&lt;p&gt;$$f(x)=\frac{1}{\beta(a,b)}x^{a-1}(1-x)^{b-1},\quad0&amp;lt;x&amp;lt;1$$&lt;/p&gt;
&lt;p&gt;$\beta(a,b)$ is the beta function. It is a constant that chosen to make the PDF integrate to 1. We write this as $X \sim \text{Beta}(a,b)$.&lt;/p&gt;
&lt;p&gt;Taking $a=b=1$, the $Beta(1,1)$ PDF is $f(x)=1$, which is same as the uniform distribution $Unif(0,1)$, the proof is shown below.&lt;/p&gt;
&lt;h2 id=&#34;beta-function&#34;&gt;Beta function
&lt;/h2&gt;&lt;p&gt;To make the PDF of Beta distribution integrate to 1. The constant $\beta(a,b)$ is defined as:&lt;/p&gt;
&lt;p&gt;$$\beta(a,b)=\int_0^1 x^{a-1}(1-x)^{b-1}dx=\frac{(a-1)!(b-1)!}{(a+b-1)!}$$&lt;/p&gt;
&lt;p&gt;$Proof.$
Let&amp;rsquo;s use the induction to prove the above equation.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Base Case:&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For $b=1$:
$$\beta(a,1)=\int_0^1x^{a-1}dx=\frac{1}{a}=\frac{(a-1)!(1-1)!}{(a+1-1)!}$$&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;Recurrence Relation of the Beta Function:&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Using integration by parts on $\beta(a,b)$:
$$\beta(a,b+1)=\frac{b}{a+b}\beta(a,b)$$&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Inductive Step:&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let&amp;rsquo;s assume the formula holds for $b=k$, i.e., $\beta(a,k)=\frac{(a-1)!(k-1)!}{(a+k-1)!}$.&lt;/p&gt;
&lt;p&gt;Then we have:
$$\beta(a,k+1)=\int_0^1 x^{a-1}(1-x)^{k}dx=\int_0^1 x^{a-1}(1-x)^{k}dx$$
As shown in 2, we can write:
$$\beta(a,k+1)=\frac{k}{a+k}\int_0^1 x^{a-1}(1-x)^{k-1}dx$$
$$=\frac{k}{a+k}\cdot\frac{(a-1)!(k-1)!}{(a+k-1)!}$$
$$=\frac{(a-1)!(k)!}{(a+k)!}$$
Thus, we have shown that if the formula holds for $b=k$, it also holds for $b=k+1$.&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Conclusion:&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;By the principle of mathematical induction, the formula holds for all positive integers $b$. Symmetrically, we can also show that the formula holds for $a$ by using the same induction process.&lt;/p&gt;
&lt;h2 id=&#34;beta-binomial-conjugacy&#34;&gt;Beta-Binomial conjugacy
&lt;/h2&gt;&lt;p&gt;The Beta distribution is the conjugate prior of the Binomial distribution. This means that if we have a Binomial likelihood and a Beta prior, the posterior distribution will also be a Beta distribution.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s say we have a coin that we want to test for bias. We flip the coin $n$ times and observe $k$ heads. We can model this with a Binomial distribution, where the probability of heads is $p$. The likelihood function is given by:
$$P(X=k|p)=\binom{n}{k}p^k(1-p)^{n-k}$$
where $X$ is the number of heads observed in $n$ flips.
The likelihood function is a function of $p$, and it tells us how likely we are to observe $k$ heads given a particular value of $p$.&lt;/p&gt;
&lt;p&gt;For example, if we have a Binomial likelihood with parameters $n$ and $k$, and a Beta prior with parameters $a$ and $b$, the posterior distribution will be:&lt;/p&gt;
&lt;p&gt;$$f(p|X=k)=\frac{P(X=k|p)f(p)}{P(X=k)}=\frac{(_k^n)p^k(1-p)^{n-k}\cdot\frac{1}{\beta(a,b)}p^{a-1}(1-p)^{b-1}}{P(X=k)}$$
$$=\frac{(_k^n)p^k(1-p)^{n-k}\cdot\frac{1}{\beta(a,b)}p^{a-1}(1-p)^{b-1}}{\int_0^1P(X=k|p)f(p)dp}$$&lt;/p&gt;
&lt;p&gt;It is difficult to calculate the denominator. Are we stucked here?&lt;/p&gt;
&lt;p&gt;Acutally, the calculation is much easier than it appears. The conditional PDF $f(p|X=k)$ is a function of $p$, which means everthing that desn&amp;rsquo;t depend on $p$ is a constant. We can drop all these constants and find the PDF up to a multiplicative constant (and then the normalizing constant is whatever it needs to make the PDF integrate to 1). We can drop the $(_k^n)$, $\frac{1}{\beta(a,b)},$ and the denominator $P(X=k)$. So we can write:&lt;/p&gt;
&lt;p&gt;$$f(p|X=k)\propto p^{k+a-1}(1-p)^{n-k+b-1}$$&lt;/p&gt;
&lt;p&gt;Which is very close to the PDF of a Beta distribution $Beta(a+k, b+n-k)$, up to a multiplicative constant. Therefore, we can conclude that the posterior distribution is:&lt;/p&gt;
&lt;p&gt;$$f(p|X=k)\sim Beta(a+k, b+n-k)$$&lt;/p&gt;
</description>
        </item>
        <item>
        <title>LOTUS</title>
        <link>https://example.org/post/lotus/</link>
        <pubDate>Wed, 14 May 2025 15:10:48 +0800</pubDate>
        
        <guid>https://example.org/post/lotus/</guid>
        <description>&lt;img src="https://example.org/post/lotus/windmill.png" alt="Featured image of post LOTUS" /&gt;&lt;h2 id=&#34;definition-of-expectation&#34;&gt;Definition of expectation
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Definition (Expectation of a discrete random variable)&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The expected value of a discrete random variable $X$ whose distinct possible values are $x_1, x_2, \ldots$ is defined by
$$\mathbb E[X] = \sum_{i} x_i P(X = x_i) = \sum_{i} x_i f_X(x_i)$$
where $f_X(x)$ is the probability mass function of $X$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The expected value of a continuous random variable $X$ is defined by
$$\mathbb E[X] = \int_{-\infty}^{\infty} x f_X(x) dx$$
where $f_X(x)$ is the probability density function of $X$.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;law-of-unconscious-statistician-lotus&#34;&gt;Law of unconscious statistician (LOTUS)
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Theorem (LOTUS)&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;If $X$ is a discrete random variable, and $g$ is a function from $\mathbb R$ to $\mathbb R$. If $Y=g(X)$, then
$$\mathbb E[Y] = \mathbb E[g(X)] = \sum_{x} g(x) P(X = x) = \sum_{x} g(x) f_X(x)$$
where $f_X(x)$ is the probability mass function (PMF) of $X$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If $X$ is a continuous random variable, and $g$ is a function from $\mathbb R$ to $\mathbb R$. If $Y=g(X)$, then
$$\mathbb E[Y] = \mathbb E[g(X)] = \int_{-\infty}^{\infty} g(x) f_X(x) dx$$
where $f_X(x)$ is the probability density function (PDF) of $X$.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;why-lotus&#34;&gt;Why LOTUS?
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Example 1&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$X \sim Exponential(\lambda)$&lt;/li&gt;
&lt;li&gt;$Y=log(X)$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we use the definition of expectation to calculate $\mathbb E[Y]$, we can first calculate the PDF of $Y$:
$$f_Y(y) = \frac{d}{dy} P(Y \leq y) = \frac{d}{dy} P(X \leq e^y) = \frac{d}{dy} (1 - e^{-\lambda e^y})$$
$$= \lambda e^{-\lambda e^y} e^y = \lambda e^{-\lambda e^y + y}$$&lt;/p&gt;
&lt;p&gt;Then we can calculate $\mathbb E[Y]$:
$$\mathbb E[Y] = \int_{-\infty}^{\infty} y f_Y(y) dy = \int_{-\infty}^{\infty} y \lambda e^{-\lambda e^y + y} dy$$&lt;/p&gt;
&lt;p&gt;However, LOTUS could make it easier:
$$\mathbb E[Y] = \mathbb E[log(X)] = \int_{0}^{\infty} log(x) \lambda e^{-\lambda x} dx$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 2&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$X \sim N(0,1)$&lt;/li&gt;
&lt;li&gt;$Y = sin(X)$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we use the definition of expectation to calculate $\mathbb E[Y]$, we can first calculate the PDF of $Y$:
$$f_Y(y) = \frac{d}{dy} P(Y \leq y) = \frac{d}{dy} P(X \leq sin^{-1}(y))$$
However, there’s no closed-form PDF for $Y$ as we cannot write the analytic form of $sin^{-1}(y)$. It’s a complicated, oscillatory transformation of a normal variable. You can’t write down $f_Y(y)$ analytically. Consequently, we cannot calculate $\mathbb E[Y]$ using the definition of expectation.&lt;/p&gt;
&lt;p&gt;However, we can use LOTUS:
$$\mathbb E[Y] = \mathbb E[sin(X)] = \int_{-\infty}^{\infty} sin(x) f_X(x) dx = \int_{-\infty}^{\infty} sin(x) \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}} dx$$
This is a analytically solvable integral. The result is $0$ because the integrand is an odd function and the limits are symmetric about $0$.&lt;/p&gt;
&lt;h2 id=&#34;in-summary&#34;&gt;In summary
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;LOTUS is a powerful tool for calculating the expected value of a function of a random variable.&lt;/li&gt;
&lt;li&gt;It allows us to avoid the need to find the PDF of the transformed variable.&lt;/li&gt;
&lt;li&gt;It can simplify the calculation of expected values for complex transformations.&lt;/li&gt;
&lt;li&gt;It is applicable to both discrete and continuous random variables.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Change_of_variables</title>
        <link>https://example.org/post/change_of_variables/</link>
        <pubDate>Wed, 14 May 2025 14:35:45 +0800</pubDate>
        
        <guid>https://example.org/post/change_of_variables/</guid>
        <description>&lt;img src="https://example.org/post/change_of_variables/House.png" alt="Featured image of post Change_of_variables" /&gt;&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt; (Change of variables in one dimension) Let $X$ be a random variable with PDF $f_X$, and let $Y=g(X)$, where $g$ is differentiable and monotonic. Then the PDF of $Y$ is given by:
$$f_Y(y)=f_X(x)|\frac{dx}{dy}|$$
where $x=g^-1(y)$. The support of Y is all $g(x)$ with $x$ in the support of $X$.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Suppose g is strictly increasing. Then, for $y=g(x)$, the CDF of $Y$ is:
$$F_Y(y)=P(Y\leq y)=P(g(X)\leq y)=P(X\leq g^-1(y))=F_X(g^-1(y))=F_X(x)$$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Therefore, the PDF of $Y$ is
$$f_Y(y)=\frac{d}{dy}F_Y(y)=\frac{d}{dy}F_X(x)=\frac{dx}{dy}\frac{d}{dx}F_X(x)=f_X(x)\frac{dx}{dy}$$&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Suppose g is strictly decreasing. Then, for $y=g(x)$, the CDF of $Y$ is:
$$F_Y(y)=P(Y\leq y)=P(g(X)\leq y)=P(X\geq g^-1(y))=1-P(X\leq g^-1(y))=1-F_X(g^-1(y))=1-F_X(x)$$
Therefore, the PDF of $Y$ is
$$f_Y(y)=\frac{d}{dy}F_Y(y)=-\frac{d}{dy}F_X(x)=-\frac{dx}{dy}\frac{d}{dx}F_X(x)=-f_X(x)\frac{dx}{dy}$$
In this case, the $\frac{dx}{dy}$ is negative, so we can write:
$$f_Y(y)=f_X(x)|\frac{dx}{dy}|$$&lt;/li&gt;
&lt;li&gt;Combine the two cases:
$$f_Y(y)=f_X(x)|\frac{dx}{dy}|$$
where $x=g^-1(y)$. The support of Y is all $g(x)$ with $x$ in the support of $X$.&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Taylor Expansion / Series and Power Series</title>
        <link>https://example.org/post/taylor_expansion/</link>
        <pubDate>Tue, 13 May 2025 20:14:20 +0800</pubDate>
        
        <guid>https://example.org/post/taylor_expansion/</guid>
        <description>&lt;img src="https://example.org/post/taylor_expansion/Figure.jpg" alt="Featured image of post Taylor Expansion / Series and Power Series" /&gt;&lt;h2 id=&#34;taylor-expansion--series&#34;&gt;Taylor Expansion / Series
&lt;/h2&gt;&lt;p&gt;In mathematics, the Taylor expansion / series of a function is an infinite sum of terms that are expressed in terms of the function&amp;rsquo;s derivatives at a single point. For most common functions, the function and the sum of its Taylor series are equal near this point.&lt;/p&gt;
&lt;p&gt;Suppose $f(x)$ is a real or composite function, which is a differentiable function of a neighborhood of the point $a$. The Taylor series of $f(x)$ about the point $a$ is given by:&lt;/p&gt;
&lt;p&gt;$$f(x)=f(a)+\frac{f^{\prime}(a)}{1!}(x-a)+\frac{f^{\prime\prime}(a)}{2!}(x-a)^2+\frac{f^{\prime\prime\prime}(a)}{3!}(x-a)^3+\dots$$&lt;/p&gt;
&lt;p&gt;Where $n!$ denotes the factorial of $n$. In the more compact sigma notation, this can be written as:
$$f(x)=\sum_{n=0}^\infin\frac{f^{(n)}(a)}{n!}(x-a)^n$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: the power series for $e^x$ is:
$$e^x=\sum_{n=0}^\infty \frac{x^n}{n!}$$&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;As the derivative of $e^x$ is itself:
$$f^{(n)}(x)=e^x$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Taking the derivative at $x=0$:
$$f^{(n)}(0)=e^0=1$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Using Taylor expansion, set $a=0$:
$$f(x)=\sum_{n=0}^\infin\frac{f^{(n)}(a)}{n!}(x-a)^n=\sum_{n=0}^\infin\frac{x^n}{n!}$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;In summary&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Taylor expansion is a way to &lt;strong&gt;approximate&lt;/strong&gt; a function using infinitely many polynomial terms.&lt;/p&gt;
&lt;h2 id=&#34;power-series&#34;&gt;Power Series
&lt;/h2&gt;&lt;p&gt;A power series is an infinite series of the form:
$$\sum_{n=0}^\infty a_n(x-a)^n$$&lt;/p&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$a_n$ are the coefficients of the series&lt;/li&gt;
&lt;li&gt;$x$ is the variable&lt;/li&gt;
&lt;li&gt;$a$ is a constant.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: the power series for $sin(x)$ is:
$$sin(x)=\sum_{n=0}^\infin\frac{(-1)^nx^{2n+1}}{(2n+1)!}=x-\frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+\frac{x^9}{9!}-\frac{x^11}{11!}+\dots$$&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Proof.&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Using the Taylor expansion with $a=0$:
$$f(x)=sin(x)=\sum_{n=0}^\infin\frac{f^{(n)}(0)}{n!}(x)^n$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute the derivatives of $sin(x)$ at $x=0$:
$$f(0)=sin(0)=0$$
$$f^{(1)}(0)=cos(0)=1$$
$$f^{(2)}(0)=-sin(0)=0$$
$$f^{(3)}(0)=-cos(0)=-1$$
$$f^{(4)}(0)=sin(0)=0$$
$$f^{(5)}(0)=cos(0)=1$$
$$f^{(6)}(0)=-sin(0)=0$$
$$f^{(7)}(0)=-cos(0)=-1$$
$$\dots$$
You can see that only the odd derivatives are non-zero, and they alternate in sign.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Plug into the Taylor expansion:
$$f(x)=\sum_{n=0}^\infin\frac{f^{(n)}(0)}{n!}(x)^n=\sum_{n=0}^\infin\frac{(-1)^nx^{2n+1}}{(2n+1)!}$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;In Summary&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Every Taylor series is a power series, but not every power series is a Taylor series.&lt;/li&gt;
&lt;li&gt;Power series serve as a broad framework, while Taylor series are tailored (pun intended!) to approximate specific functions using their derivatives.&lt;/li&gt;
&lt;li&gt;The convergence of a Taylor series to its function depends on the function being analytic (i.e., equal to its Taylor series in some neighborhood).&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Moments in Probability</title>
        <link>https://example.org/post/moments/</link>
        <pubDate>Tue, 13 May 2025 00:53:25 +0800</pubDate>
        
        <guid>https://example.org/post/moments/</guid>
        <description>&lt;img src="https://example.org/post/moments/Minecraft_DH.png" alt="Featured image of post Moments in Probability" /&gt;&lt;h2 id=&#34;moments-in-probability&#34;&gt;Moments in Probability
&lt;/h2&gt;&lt;p&gt;For a random variable $X$, The $n$-th moments of $X$ is the expectation of $X^n$, which is $\mathbb{E}[X^n]$.&lt;/p&gt;
&lt;p&gt;Why we need moment? Let’s starts with some measures we often use to describe a distribution.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mean:&lt;/strong&gt; $\mu=\mathbb{E}[X]$. &lt;em&gt;Mean&lt;/em&gt; measures the central tendency. It tells us something about the center of a distribution. It is the $1$-th moment of $X$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Variance:&lt;/strong&gt; $\sigma=\mathbb{E}[X-\mu]^2$, &lt;em&gt;Variance&lt;/em&gt; measures of dispersion. It is a measure of how far a set of numbers is spread out from their average value. It is the $2$-nd moment of $X-\mu$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Skewness:&lt;/strong&gt; $Skew(X)=\mathbb{E}[\frac{X-\mu}{\sigma}]^3$. &lt;em&gt;Skewness&lt;/em&gt; measures the level of asymmetry level of a distribution. It is the $3$-rd moment of standardized $X$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Kurtosis:&lt;/strong&gt;: $Kurt(X)=\mathbb{E}[\frac{X-μ}{σ}]^4-3$. &lt;em&gt;Kurtosis&lt;/em&gt; measures the tail’s heavy level of a distribution. It is the $4$-th moment of standardized $X$. The reason for subtracting 3 is to make any Normal distribution have kurtosis of 0.&lt;/p&gt;
&lt;p&gt;As we can see from the example, moment could be used to measure the characteristics of distributions.&lt;/p&gt;
&lt;h2 id=&#34;sample-moments&#34;&gt;Sample moments
&lt;/h2&gt;&lt;p&gt;In previous section, we used some examples to introduce the moment, and why we need it. We used $\mathbb{E}[X]$, which is the $1$-st moment of $X$, to represent the mean. Back to primary school, we were taught to use $\bar{X}=\frac{1}{n}\sum_{i=1}^nx_i$ to calculate the mean of a observed data. For example, if we observe a list of $[1,3,4,2,2,6]$, the mean of this list would be $(1+3+4+2+2+6)/6=3$. Here is the question, what is the difference between $\mathbb{E}[X]$ and $\bar{X}$?&lt;/p&gt;
&lt;p&gt;In probability, we use $\mathbb{E}[X]$ to represent the mean of a random variable $X$. In statistics, we use $\bar{X}$ to represent the mean of a observed data (sampled data, also called sample). $\mathbb{E}[X]$ is the population mean of a random variable. Let&amp;rsquo;s say $X \backsim N(0,1)$, then the $\mathbb{E}[X]$ is equal to $0$. While $\bar{X}$ is the sample mean of a observed data. In the real situation, we can only observe a sample of $X$, not the whole population. Therefore, the $\bar{X}$ calculated from $\frac{1}{n}\sum_{i=1}^nx_i$ might not eactly equal to $0$. As the sample mean $\bar{X}$ is an estimate of the population mean $\mathbb{E}[X]$.&lt;/p&gt;
&lt;p&gt;Similarly, the sample variance is defined as:
$$ S_n^2=\frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})^2 $$
The sample variance $S_n^2$ is an estimate of the population variance $\sigma^2$. The sample variance is an unbiased estimator of the population variance. The reason for using $n-1$ instead of $n$ is to make the sample variance an unbiased estimator of the population variance. If we use $n$, then the sample variance would be biased.&lt;/p&gt;
&lt;p&gt;Similarly, we can define the &lt;em&gt;sample skewness&lt;/em&gt; as:
$$ S_n^3=\frac{1}{n}\sum_{i=1}^n(\frac{x_i-\bar{x}}{S_n})^3 $$
and the &lt;em&gt;sample kurtosis&lt;/em&gt; as:
$$ S_n^4=\frac{1}{n}\sum_{i=1}^n(\frac{x_i-\bar{x}}{S_n})^4-3 $$&lt;/p&gt;
&lt;h2 id=&#34;moment-generating-functions&#34;&gt;Moment generating functions
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt; (Moment via derivatives of the MGF). The moment generating function (MGF) of a random variable $X$ is defined as:
$$ M_X(t)=\mathbb{E}[e^{tX}] $$
Given the MGF of $X$, we can get the $n$-th moment of $X$ by taking the $n$-th derivative of the MGF and evaluating it at $t=0$: $$\mathbb{E}[X^n]=M^{(n)}(0)$$&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Proof&lt;/em&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Using Taylor expansion of $M_X(t)$ around $t=0$:
$$M_X(t)=\mathbb{E}[e^{tX}]=\sum_{n=0}^\infin M^{(0)}(0)\frac{t^n}{n!} \tag{1}$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Using Power series expansion of $e^{tX}$:
$$e^{tX}=\sum_{n=0}^\infin \frac{(tX)^n}{n!}=\sum_{n=0}^\infin \frac{t^nX^n}{n!}$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;So the expectation of $e^{tX}$ is:
$$\mathbb{E}[e^{tX}]=\sum_{n=0}^\infin \frac{t^n}{n!}\mathbb{E}[X^n] \tag{2}$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Comparing (1) and (2), we can get:
$$\mathbb{E}[X^n]=M^{(n)}(0)$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This theorem is suprising in that for a continuous random variable $X$, to compute moments would seemingly require doing integrals with LOTUS, but with the MGF, it is possible to find moments by taking derivatives rather than doing integrals.&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
